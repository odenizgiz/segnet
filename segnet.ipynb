{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segnet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "import math\n",
    "import os \n",
    "import cv2 \n",
    "from math import ceil\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 300\n",
    "IMAGE_WIDTH = 600 \n",
    "IMAGE_DEPTH = 3 \n",
    "RESIZED_IMAGE_HEIGHT = 256 \n",
    "RESIZED_IMAGE_WIDTH = 512\n",
    "\n",
    "NUM_CLASSES = 2 \n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 25\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TEST = 2\n",
    "NUM_EXAMPLES_FOR_EPOCH_FOR_EVAL = 2\n",
    "BATCH_SIZE = 3\n",
    "TEST_ITER = NUM_EXAMPLES_PER_EPOCH_FOR_TEST / BATCH_SIZE\n",
    "\n",
    "NUM_LABELS = 2 \n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "\n",
    "INITIAL_LEARNING_RATE = 0.001      # Initial learning rate.\n",
    "EVAL_BATCH_SIZE = 1\n",
    "OPTIMIZER = \"adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P> <P/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/data/dataset_example/' # '/Users/odeniz/Dropbox/data-science/Deep Learning/Semantic Segmentation/dataset_example/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = tf.train.string_input_producer([os.path.join(data_dir, 'images/%d.jpg' % i) for i in range(0, 27)]) \n",
    "filenames_labels = tf.train.string_input_producer([os.path.join(data_dir, 'masks/%d.jpg' % i) for i in range(0, 27)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size, shuffle):\n",
    "    \n",
    "    \"\"\" construct a queued batch of images and labels. \n",
    "    \n",
    "    Args: \n",
    "        image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "        label: 1-D Tensor of type.int32\n",
    "        min_queue_examples: int32, minimum number of samples to retain \n",
    "            in the queue that provides the batches of examples \n",
    "        batch_size: Number of images per batch \n",
    "        shuffle: boolean indicating whether to use a shuffling queue. \n",
    "    \n",
    "   Returns: \n",
    "       images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "       labels: Labels. 1D tensor of [batch_size] size. \n",
    "     \"\"\"\n",
    "    \n",
    "    # create a queue that shuffles the examples, and then read \n",
    "    # 'batch_size' images + labels from the example queue. \n",
    "    num_preprocess_threads = 1 # 16\n",
    "    if shuffle: \n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label], \n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads, \n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "        \n",
    "    else: \n",
    "        images, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size)\n",
    "        \n",
    "    # display the training images in the visualizer\n",
    "    tf.summary.image('images', images)\n",
    "    \n",
    "    return images, label_batch  # tf.reshape(label_batch, [batch_size])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(data_dir, validation, batch_size):\n",
    "    \"\"\" construct augmented input\n",
    "    \n",
    "        data_dir: path to data directory\n",
    "        batch_size: number of images per batch\n",
    "        \n",
    "        Returns: \n",
    "        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "        labels: Labels. 1D tensor of [batch_size] size. \n",
    "    \"\"\"\n",
    "    if validation: \n",
    "        filenames = [os.path.join(data_dir, 'validation/images/%d.jpg' % i) for i in range(27, 53)] \n",
    "        filenames_labels = [os.path.join(data_dir, 'validation/masks/%d.png' % i) for i in range(27, 53)]\n",
    "    else: \n",
    "        filenames = [os.path.join(data_dir, 'images/%d.jpg' % i) for i in range(0, 26)] \n",
    "        filenames_labels = [os.path.join(data_dir, 'masks/%d.png' % i) for i in range(0, 26)] \n",
    "    \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "            \n",
    "    for f in filenames_labels:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "\n",
    "            \n",
    "    # create a queue that produces the filenames to read\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    filename_label_queue = tf.train.string_input_producer(filenames_labels)\n",
    "    \n",
    "\n",
    "    reader = tf.WholeFileReader()\n",
    "    _, imageValue = reader.read(filename_queue)\n",
    "    image_bytes = tf.image.decode_image(imageValue)\n",
    "    image = tf.reshape(image_bytes, (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))\n",
    "    reshaped_image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # read labels \n",
    "#     read_input_labels = read_data(filename_label_queue)\n",
    "#     label = read_input_labels.float32image\n",
    "    _, labelValue = reader.read(filename_label_queue)\n",
    "    label_bytes = tf.image.decode_image(labelValue)\n",
    "    label = tf.reshape(label_bytes, (IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n",
    "    \n",
    "    \n",
    "    height = RESIZED_IMAGE_HEIGHT\n",
    "    width = RESIZED_IMAGE_WIDTH\n",
    "    \n",
    "    \n",
    "    # CHANGE. RANDOMIZE THESE OPERATIONS HERE. \n",
    "    # because these operations are not commutative, consider randomizing \n",
    "    # the order of their operation. \n",
    "    \n",
    "    #############################################\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "    # randomly crop the image horizontally. \n",
    "#     distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    \n",
    "    # subtract off the mean and divide by the variance of the pixels. \n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    resized_label = tf.random_crop(label, [height, width, 1])\n",
    "    #############################################\n",
    "    \n",
    "    # set the shapes of tensors.\n",
    "#     float_image.set_shape([height, width, 3])\n",
    "#     label.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "    \n",
    "    # ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "    \n",
    "    print (\"Filling queue with %d images before starting to train. This will take a few minutes. \"\n",
    "          % min_queue_examples)\n",
    "\n",
    "\n",
    "      \n",
    "    # generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, resized_label,\n",
    "                                          min_queue_examples, batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    with tf.device('/gpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, initializer, wd):\n",
    "    \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "    Note that the Variable is initialized with a truncated normal distribution.\n",
    "    A weight decay is added only if one is specified.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      initializer)\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses.\n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "    Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "    # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name +' (raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "    return loss_averages_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def msra_initializer(kl, dl):\n",
    "    \"\"\"\n",
    "    kl for kernel size, dl for filter number\n",
    "    \"\"\"\n",
    "    stddev = math.sqrt(2. / (kl**2 * dl))\n",
    "    return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "\n",
    "def orthogonal_initializer(scale = 1.1):\n",
    "    ''' From Lasagne and Keras. Reference: Saxe et al., http://arxiv.org/abs/1312.6120\n",
    "    '''\n",
    "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
    "        flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
    "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "        # pick the one with the correct shape\n",
    "        q = u if u.shape == flat_shape else v\n",
    "        q = q.reshape(shape) #this needs to be corrected to float32\n",
    "        return tf.constant(scale * q[:shape[0], :shape[1]], dtype=tf.float32)\n",
    "    return _initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weight_initializer():\n",
    "    if(CONV_INIT == \"var_scale\"):\n",
    "        initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    elif(CONV_INIT == \"xavier\"):\n",
    "        initializer=tf.contrib.layers.xavier_initializer()\n",
    "    else:\n",
    "        raise ValueError(\"Chosen weight initializer does not exist\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "    \"\"\"\n",
    "      loss func without re-weighting\n",
    "    \"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    logits = tf.reshape(logits, (-1,NUM_CLASSES))\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      logits=logits, labels=labels, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def weighted_loss(logits, labels, num_classes, head=None):\n",
    "    \"\"\" median-frequency re-weighting \"\"\"\n",
    "    with tf.name_scope('loss'):\n",
    "\n",
    "        logits = tf.reshape(logits, (-1, num_classes))\n",
    "\n",
    "        epsilon = tf.constant(value=1e-10)\n",
    "\n",
    "        logits = logits + epsilon\n",
    "\n",
    "        # construct one-hot label array\n",
    "        label_flat = tf.reshape(labels, (-1, 1))\n",
    "\n",
    "        # should be [batch ,num_classes]\n",
    "        labels = tf.reshape(tf.one_hot(label_flat, depth=num_classes), (-1, num_classes))\n",
    "\n",
    "        softmax = tf.nn.softmax(logits)\n",
    "\n",
    "        cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax + epsilon), head), axis=[1])\n",
    "\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "\n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def cal_loss(logits, labels):\n",
    "    loss_weight = np.array([\n",
    "      0.2595,\n",
    "      0.1826,\n",
    "      4.5640,\n",
    "      0.1417,\n",
    "      0.9051,\n",
    "      0.3826,\n",
    "      9.6446,\n",
    "      1.8418,\n",
    "      0.6823,\n",
    "      6.2478,\n",
    "      7.3614,\n",
    "      1.0974]) # class 0~11\n",
    "\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    return loss(logits, labels)\n",
    "    # now return weighted_loss(logits, labels, num_classes=NUM_CLASSES, head=loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_calc(logits, labels):\n",
    "    \"\"\"\n",
    "        logits: tensor, float - [batch_size, width, height, num_classes].\n",
    "        labels: tensor, int32 - [batch_size, width, height, num_classes].\n",
    "    \"\"\"\n",
    "    # construct one-hot label array\n",
    "    label_flat = tf.reshape(labels, (-1, 1))\n",
    "    labels = tf.reshape(tf.one_hot(label_flat, depth=NUM_CLASSES), (-1, NUM_CLASSES))\n",
    "\n",
    "    #This motif is needed to hook up the batch_norm updates to the training\n",
    "#     update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "#     with tf.control_dependencies(update_ops):\n",
    "#         cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "#         tf.summary.scalar('loss', cross_entropy)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    tf.summary.scalar('loss', cross_entropy)\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def unpool_with_argmax(pool, ind, name = None, ksize=[1, 2, 2, 1]):\n",
    "\n",
    "    \"\"\"\n",
    "       Unpooling layer after max_pool_with_argmax.\n",
    "       Args:\n",
    "           pool:   max pooled output tensor\n",
    "           ind:      argmax indices\n",
    "           ksize:     ksize is the same as for the pool\n",
    "       Return:\n",
    "           unpool:    unpooling tensor\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        input_shape = pool.get_shape().as_list()\n",
    "        output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n",
    "\n",
    "        flat_input_size = np.prod(input_shape)\n",
    "        flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]\n",
    "\n",
    "        pool_ = tf.reshape(pool, [flat_input_size])\n",
    "        batch_range = tf.reshape(tf.range(output_shape[0], dtype=ind.dtype), shape=[input_shape[0], 1, 1, 1])\n",
    "        b = tf.ones_like(ind) * batch_range\n",
    "        b = tf.reshape(b, [flat_input_size, 1])\n",
    "        ind_ = tf.reshape(ind, [flat_input_size, 1])\n",
    "        ind_ = tf.concat([b, ind_], 1)\n",
    "\n",
    "        ret = tf.scatter_nd(ind_, pool_, shape=flat_output_shape)\n",
    "        ret = tf.reshape(ret, output_shape)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer_with_bn(inputT, shape, train_phase, activation=True, name=None):\n",
    "    in_channel = shape[2]\n",
    "    out_channel = shape[3]\n",
    "    k_size = shape[0]\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        kernel = _variable_with_weight_decay('ort_weights', shape=shape, initializer=orthogonal_initializer(), wd=None)\n",
    "        conv = tf.nn.conv2d(inputT, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [out_channel], tf.constant_initializer(0.0))\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        if activation is True:\n",
    "            conv_out = tf.nn.relu(batch_norm_layer(bias, train_phase, scope.name))\n",
    "        else:\n",
    "            conv_out = batch_norm_layer(bias, train_phase, scope.name)\n",
    "    return conv_out\n",
    "\n",
    "def get_deconv_filter(f_shape):\n",
    "    \"\"\"\n",
    "       reference: https://github.com/MarvinTeichmann/tensorflow-fcn\n",
    "    \"\"\"\n",
    "    width = f_shape[0]\n",
    "    height = f_shape[0]\n",
    "    f = ceil(width/2.0)\n",
    "    c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "    bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "            bilinear[x, y] = value\n",
    "    weights = np.zeros(f_shape)\n",
    "    for i in range(f_shape[2]):\n",
    "        weights[:, :, i, i] = bilinear\n",
    "\n",
    "    init = tf.constant_initializer(value=weights,\n",
    "                                 dtype=tf.float32)\n",
    "    return tf.get_variable(name=\"up_filter\", initializer=init,\n",
    "                         shape=weights.shape)\n",
    "\n",
    "\n",
    "\n",
    "def deconv_layer(inputT, f_shape, output_shape, stride=2, name=None):\n",
    "    # output_shape = [b, w, h, c]\n",
    "    # sess_temp = tf.InteractiveSession()\n",
    "    sess_temp = tf.global_variables_initializer()\n",
    "    strides = [1, stride, stride, 1]\n",
    "    with tf.variable_scope(name):\n",
    "        weights = get_deconv_filter(f_shape)\n",
    "        deconv = tf.nn.conv2d_transpose(inputT, weights, output_shape,\n",
    "                                        strides=strides, padding='SAME')\n",
    "    return deconv\n",
    "\n",
    "\n",
    "def batch_norm_layer(inputT, is_training, scope):\n",
    "    return tf.cond(is_training,\n",
    "          lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,\n",
    "                           center=False, updates_collections=None, scope=scope+\"_bn\"),\n",
    "          lambda: tf.contrib.layers.batch_norm(inputT, is_training=False,\n",
    "                           updates_collections=None, center=False, scope=scope+\"_bn\", reuse = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, batch_size, phase_train):\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(images, depth_radius=5, bias=1.0, alpha=0.0001, beta=0.75,\n",
    "                name='norm1')\n",
    "    # conv1\n",
    "    conv1 = conv_layer_with_bn(norm1, [7, 7, images.get_shape().as_list()[3], 64], phase_train, name=\"conv1\")\n",
    "    print (\"conv1 shape is: \", conv1.get_shape())\n",
    "    # pool1\n",
    "    pool1, pool1_indices = tf.nn.max_pool_with_argmax(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME', name='pool1')\n",
    "    print (\"pool1 shape is: \", pool1.get_shape())\n",
    "    \n",
    "    \n",
    "    # conv2\n",
    "    conv2 = conv_layer_with_bn(pool1, [7, 7, 64, 64], phase_train, name=\"conv2\")\n",
    "    print (\"conv2 shape is: \", conv2.get_shape())\n",
    "    \n",
    "    # pool2\n",
    "    pool2, pool2_indices = tf.nn.max_pool_with_argmax(conv2, ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    print (\"pool2 shape is: \", pool2.get_shape())\n",
    "    \n",
    "    \n",
    "    # conv3\n",
    "    conv3 = conv_layer_with_bn(pool2, [7, 7, 64, 64], phase_train, name=\"conv3\")\n",
    "    print (\"conv3 shape is: \", conv3.get_shape())\n",
    "    \n",
    "    # pool3\n",
    "    pool3, pool3_indices = tf.nn.max_pool_with_argmax(conv3, ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "    print (\"pool3 shape is: \", pool3.get_shape())\n",
    "    \n",
    "    \n",
    "    # conv4\n",
    "    conv4 = conv_layer_with_bn(pool3, [7, 7, 64, 64], phase_train, name=\"conv4\")\n",
    "    print (\"conv4 shape is: \", conv4.get_shape())\n",
    "    \n",
    "    # pool4\n",
    "    pool4, pool4_indices = tf.nn.max_pool_with_argmax(conv4, ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1], padding='SAME', name='pool4')\n",
    "    print (\"pool4 shape is: \", pool4.get_shape())\n",
    "\n",
    "    \"\"\" End of encoder \"\"\"\n",
    "    \n",
    "    \"\"\" start upsample \"\"\"\n",
    "    # upsample4\n",
    "    # Need to change when using different dataset out_w, out_h\n",
    "#     upsample4 = upsample_with_pool_indices(pool4, pool4_indices, pool4.get_shape(), out_w=45, out_h=60, scale=2, name='upsample4')\n",
    "#     upsample4 = deconv_layer(pool4, [2, 2, 64, 64], pool4.get_shape(), 2, \"up4\") # [batch_size, 45, 60, 64]\n",
    "    # decode 4\n",
    "    print (\"pool4 shape is: \", pool4.get_shape())\n",
    "    unpool_4 = unpool_with_argmax(pool4, ind=pool4_indices, name='unpool_4')\n",
    "    print (\"unpool4 shape is: \", unpool_4.get_shape())\n",
    "    conv_decode4 = conv_layer_with_bn(unpool_4, [7, 7, 64, 64], phase_train, False, name=\"conv_decode4\")\n",
    "    print (\"conv_decode4 shape is: \", conv_decode4.get_shape())\n",
    "    print (\"\")\n",
    "    # upsample 3\n",
    "#     upsample3 = upsample_with_pool_indices(conv_decode4, pool3_indices, conv_decode4.get_shape(), scale=2, name='upsample3') \n",
    "#     upsample3= deconv_layer(conv_decode4, [2, 2, 64, 64], conv_decode4.get_shape(), 2, \"up3\") # [batch_size, 90, 120, 64]\n",
    "    # decode 3\n",
    "    \n",
    "    print (\"pool3 shape is: \", pool3.get_shape())\n",
    "    unpool_3 = unpool_with_argmax(conv_decode4, ind=pool3_indices, name='unpool_3')\n",
    "    print (\"unpool_3 shape is: \", unpool_3.get_shape())\n",
    "    conv_decode3 = conv_layer_with_bn(unpool_3, [7, 7, 64, 64], phase_train, False, name=\"conv_decode3\")\n",
    "    print (\"conv_decode3 shape is: \", conv_decode3.get_shape())\n",
    "    print (\"\")\n",
    "    # upsample2\n",
    "#     upsample2 = upsample_with_pool_indices(conv_decode3, pool2_indices, conv_decode3.get_shape(), scale=2, name='upsample2')\n",
    "#     upsample2= deconv_layer(conv_decode3, [2, 2, 64, 64], conv_decode3.get_shape(), 2, \"up2\") #  [batch_size, 180, 240, 64]\n",
    "    # decode 2\n",
    "    print (\"pool2 shape is: \", pool2.get_shape())\n",
    "    unpool_2 = unpool_with_argmax(conv_decode3, ind=pool2_indices, name='unpool_2')\n",
    "    print (\"unpool_2 shape is: \", unpool_2.get_shape())\n",
    "    conv_decode2 = conv_layer_with_bn(unpool_2, [7, 7, 64, 64], phase_train, False, name=\"conv_decode2\")\n",
    "    print (\"conv_decode2 shape is: \", conv_decode2.get_shape())\n",
    "    print (\"\")\n",
    "    \n",
    "    # upsample1\n",
    "#     upsample1 = upsample_with_pool_indices(conv_decode2, pool1_indices, conv_decode2.get_shape(), scale=2, name='upsample1')\n",
    "#     upsample1= deconv_layer(conv_decode2, [2, 2, 64, 64], [batch_size, RESIZED_IMAGE_HEIGHT, RESIZED_IMAGE_WIDTH, 64], 2, \"up1\") # \n",
    "    # decode4\n",
    "    print (\"pool1 shape is: \", pool1.get_shape())\n",
    "    unpool_1 = unpool_with_argmax(conv_decode2, ind=pool1_indices, name='unpool_1')\n",
    "    print (\"unpool_1 shape is: \", unpool_1.get_shape())\n",
    "    conv_decode1 = conv_layer_with_bn(unpool_1, [7, 7, 64, 64], phase_train, False, name=\"conv_decode1\")\n",
    "    print (\"conv_decode1 shape is: \", conv_decode1.get_shape())\n",
    "    print (\"\")\n",
    "    \n",
    "    \"\"\" end of Decode \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\" Start Classify \"\"\"\n",
    "    # output predicted class number (6)\n",
    "#     initializer = get_weight_initializer()\n",
    "    with tf.variable_scope('conv_classifier') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                           shape=[1, 1, 64, NUM_CLASSES],\n",
    "                                           initializer=msra_initializer(1, 64),\n",
    "                                           wd=0.0005)\n",
    "        conv = tf.nn.conv2d(conv_decode1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES], tf.constant_initializer(0.0))\n",
    "        print (\"conv shape is: \", conv.get_shape())\n",
    "        print (\"biases shape is: \", biases.get_shape())\n",
    "        conv_classifier = tf.nn.bias_add(conv, biases, name=scope.name)\n",
    "\n",
    "    logit = conv_classifier\n",
    "#     loss = cal_loss(conv_classifier, labels)\n",
    "\n",
    "#     return loss, logit\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Session: Train & Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants describing the training process. \n",
    "MOVING_AVERAGE_DECAY = 0.9999    # the decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0     # Epochs after which learning rate decays. \n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1 # Learning rate decay factor. \n",
    "INITIAL_LEARNING_RATE = 0.1      # Initial learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(total_loss, global_step):\n",
    "    total_sample = 27\n",
    "    num_batches_per_epoch = 27/1\n",
    "    \"\"\" fix lr \"\"\"\n",
    "    lr = INITIAL_LEARNING_RATE\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        opt = tf.train.AdamOptimizer(lr)\n",
    "        grads = opt.compute_gradients(total_loss)\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    for grad, var in grads:\n",
    "        if grad is not None:\n",
    "            tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(is_finetune=False):\n",
    "#     max_steps = 20000\n",
    "    max_steps = 2000\n",
    "    batch_size = BATCH_SIZE\n",
    "    max_steps = MAX_STEPS\n",
    "    train_dir = LOG_DIR # /tmp3/first350/TensorFlow/Logs\n",
    "    image_w = RESIZED_IMAGE_WIDTH\n",
    "    image_h = RESIZED_IMAGE_HEIGHT\n",
    "    image_c = IMAGE_DEPTH\n",
    "    # should be changed if your model stored by different convention\n",
    "    startstep = 0 # if not is_finetune else int(FLAGS.finetune.split('-')[-1])\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        train_data_node = tf.placeholder( tf.float32, shape=[batch_size, image_h, image_w, image_c])\n",
    "        train_labels_node = tf.placeholder(tf.int64, shape=[batch_size, image_h, image_w, 1])\n",
    "        phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        \n",
    "        images, labels = distorted_inputs(data_dir=data_dir, validation=False, batch_size=BATCH_SIZE)\n",
    "        val_images, val_labels = distorted_inputs(data_dir=data_dir, validation=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Build a Graph that computes the logits predictions from the inference model.\n",
    "        eval_prediction = inference(train_data_node, batch_size, phase_train)\n",
    "        loss = loss_calc(eval_prediction, train_labels_node)\n",
    "#         loss = cal_loss(eval_prediction, train_labels_node)\n",
    "\n",
    "        # Build a Graph that trains the model with one batch of examples and updates the model parameters.\n",
    "        train_op =  train(loss, global_step) # train(loss)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.0001)\n",
    "\n",
    "        \n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            # Build an initialization operation to run below.\n",
    "            if (is_finetune == True):\n",
    "                saver.restore(sess, finetune_ckpt )\n",
    "            else:\n",
    "                init = tf.global_variables_initializer()\n",
    "                sess.run(init)\n",
    "\n",
    "            # Start the queue runners.\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "            # Summery placeholders\n",
    "            summary_writer = tf.summary.FileWriter(train_dir, sess.graph)\n",
    "            average_pl = tf.placeholder(tf.float32)\n",
    "            acc_pl = tf.placeholder(tf.float32)\n",
    "            iu_pl = tf.placeholder(tf.float32)\n",
    "            average_summary = tf.summary.scalar(\"test_average_loss\", average_pl)\n",
    "            acc_summary = tf.summary.scalar(\"test_accuracy\", acc_pl)\n",
    "            iu_summary = tf.summary.scalar(\"Mean_IU\", iu_pl)\n",
    "\n",
    "            for step in range(startstep, startstep + max_steps):\n",
    "                image_batch ,label_batch = sess.run([images, labels])\n",
    "                # since we still use mini-batches in validation, still set bn-layer phase_train = True\n",
    "                feed_dict = {\n",
    "                  train_data_node: image_batch,\n",
    "                  train_labels_node: label_batch,\n",
    "                  phase_train: True\n",
    "                }\n",
    "                start_time = time.time()\n",
    "\n",
    "                _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "                duration = time.time() - start_time\n",
    "\n",
    "                assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    num_examples_per_step = batch_size\n",
    "                    examples_per_sec = num_examples_per_step / duration\n",
    "                    sec_per_batch = float(duration)\n",
    "\n",
    "                    format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                              'sec/batch)')\n",
    "                    print (format_str % (datetime.now(), step, loss_value,\n",
    "                                       examples_per_sec, sec_per_batch))\n",
    "\n",
    "                    # eval current training batch pre-class accuracy\n",
    "                    pred = sess.run(eval_prediction, feed_dict=feed_dict)\n",
    "                    per_class_acc(pred, label_batch)\n",
    "\n",
    "                if step % 100 == 0:\n",
    "                    print(\"start validating.....\")\n",
    "                    total_val_loss = 0.0\n",
    "                    hist = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
    "                    for test_step in range(int(TEST_ITER)):\n",
    "                        val_images_batch, val_labels_batch = sess.run([val_images, val_labels])\n",
    "\n",
    "                        _val_loss, _val_pred = sess.run([loss, eval_prediction], feed_dict={\n",
    "                          train_data_node: val_images_batch,\n",
    "                          train_labels_node: val_labels_batch,\n",
    "                          phase_train: True\n",
    "                        })\n",
    "                        total_val_loss += _val_loss\n",
    "                        hist += get_hist(_val_pred, val_labels_batch)\n",
    "                    print(\"val loss: \", total_val_loss / TEST_ITER)\n",
    "                    acc_total = np.diag(hist).sum() / hist.sum()\n",
    "                    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "                    test_summary_str = sess.run(average_summary, feed_dict={average_pl: total_val_loss / TEST_ITER})\n",
    "                    acc_summary_str = sess.run(acc_summary, feed_dict={acc_pl: acc_total})\n",
    "                    iu_summary_str = sess.run(iu_summary, feed_dict={iu_pl: np.nanmean(iu)})\n",
    "                    print_hist_summery(hist)\n",
    "                    print(\" end validating.... \")\n",
    "\n",
    "                    summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                    summary_writer.add_summary(summary_str, step)\n",
    "                    summary_writer.add_summary(test_summary_str, step)\n",
    "                    summary_writer.add_summary(acc_summary_str, step)\n",
    "                    summary_writer.add_summary(iu_summary_str, step)\n",
    "                # Save the model checkpoint periodically.\n",
    "                if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "                    checkpoint_path = os.path.join(train_dir, 'model.ckpt')\n",
    "                    saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_ckpt_dir =\n",
    "LOG_DIR = '/Users/odeniz/Dropbox/data-science/Deep Learning/Semantic Segmentation/dataset_example/logs'\n",
    "res_output_dir = '/data/dataset_example/test_results'\n",
    "# '/Users/odeniz/Dropbox/data-science/Deep Learning/Semantic Segmentation/dataset_example/test_results'\n",
    "SAVA_IMAGE = True\n",
    "CONV_INIT = \"var_scale\"\n",
    "finetune_ckpt = ''\n",
    "TESTING = ''\n",
    "MAX_STEPS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def per_class_acc(predictions, label_tensor):\n",
    "    labels = label_tensor\n",
    "    num_class = NUM_CLASSES\n",
    "    size = predictions.shape[0]\n",
    "    hist = np.zeros((num_class, num_class))\n",
    "    for i in range(size):\n",
    "        hist += fast_hist(labels[i].flatten(), predictions[i].argmax(2).flatten(), num_class)\n",
    "    acc_total = np.diag(hist).sum() / hist.sum()\n",
    "    print ('accuracy = %f'%np.nanmean(acc_total))\n",
    "    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "    print ('mean IU  = %f'%np.nanmean(iu))\n",
    "    for ii in range(num_class):\n",
    "        if float(hist.sum(1)[ii]) == 0:\n",
    "            acc = 0.0\n",
    "        else:\n",
    "            acc = np.diag(hist)[ii] / float(hist.sum(1)[ii])\n",
    "        print(\"    class # %d accuracy = %f \"%(ii,acc))\n",
    "\n",
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
    "\n",
    "def get_hist(predictions, labels):\n",
    "    num_class = predictions.shape[3] #becomes 2 for aerial - correct\n",
    "    batch_size = predictions.shape[0]\n",
    "    hist = np.zeros((num_class, num_class))\n",
    "    for i in range(batch_size):\n",
    "        hist += fast_hist(labels[i].flatten(), predictions[i].argmax(2).flatten(), num_class)\n",
    "    return hist\n",
    "\n",
    "def print_hist_summery(hist):\n",
    "    acc_total = np.diag(hist).sum() / hist.sum()\n",
    "    print ('accuracy = %f'%np.nanmean(acc_total))\n",
    "    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "    print ('mean IU  = %f'%np.nanmean(iu))\n",
    "    for ii in range(hist.shape[0]):\n",
    "        if float(hist.sum(1)[ii]) == 0:\n",
    "            acc = 0.0\n",
    "        else:\n",
    "            acc = np.diag(hist)[ii] / float(hist.sum(1)[ii])\n",
    "        print(\"    class # %d accuracy = %f \"%(ii, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    image_w = RESIZED_IMAGE_WIDTH\n",
    "    image_h = RESIZED_IMAGE_HEIGHT\n",
    "    image_c = IMAGE_DEPTH\n",
    "    images = tf.placeholder(tf.float32, shape=[batch_size, image_h, image_w, IMAGE_DEPTH])\n",
    "    labels = tf.placeholder(tf.int64, [batch_size, image_h, image_w, 1])\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "\n",
    "    return images, labels, is_training, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename_list(path):\n",
    "    \n",
    "    image_filenames = sorted(os.listdir(path+'/images')) #sort by names to get img and label after each other\n",
    "    label_filenames = sorted(os.listdir(path+'/masks')) #sort by names to get img and label after each other\n",
    "    \n",
    "    #Adding correct path to the each filename in the lists\n",
    "    step=0\n",
    "    for name in image_filenames:\n",
    "            image_filenames[step] = path+\"/images/\"+name\n",
    "            step=step+1\n",
    "    step=0\n",
    "    for name in label_filenames:\n",
    "        label_filenames[step] = path+\"/masks/\"+name\n",
    "        step=step+1\n",
    "\n",
    "    return image_filenames, label_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_filename_list2(path):\n",
    "    \n",
    "    image_filenames = sorted(glob.glob(path+'/images/*.jpg'))\n",
    "    label_filenames = sorted(glob.glob(path+'/masks/*.png'))\n",
    "    \n",
    "    return image_filenames, label_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_test_data(im_list, la_list):\n",
    "    images = []\n",
    "    labels = []\n",
    "    index = 0\n",
    "    for im_filename, la_filename in zip(im_list, la_list):      \n",
    "        im = skimage.io.imread(im_filename)\n",
    "        im = skimage.transform.resize(im, (RESIZED_IMAGE_HEIGHT, RESIZED_IMAGE_WIDTH), preserve_range=True)\n",
    "        im = np.array(im, np.float32)\n",
    "        im = im[np.newaxis]\n",
    "        la = skimage.io.imread(la_filename)\n",
    "        la = skimage.transform.resize(la, (RESIZED_IMAGE_HEIGHT, RESIZED_IMAGE_WIDTH), preserve_range=True)\n",
    "        la = la[np.newaxis]\n",
    "        la = la[...,np.newaxis]\n",
    "        images.append(im)\n",
    "        labels.append(la)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_dir = '/data/dataset_example/validation'\n",
    "# '/Users/odeniz/Dropbox/data-science/Deep Learning/Semantic Segmentation/dataset_example/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    print(\"----------- In test method ----------\")\n",
    "    \n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        \n",
    "        test_data_node, test_labels_node, is_training, keep_prob = placeholder_inputs(BATCH_SIZE)  \n",
    "        image_filenames, label_filenames = get_filename_list2(val_dir)\n",
    "        images, labels = get_all_test_data(image_filenames, label_filenames)\n",
    "\n",
    "        logits = inference(test_data_node, BATCH_SIZE, is_training)\n",
    "        pred = tf.argmax(logits, axis=3)\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "    #         saver.restore(sess, model_ckpt_dir)\n",
    "\n",
    "\n",
    "            # Start the queue runners.\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)        \n",
    "            hist = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
    "\n",
    "            step=0\n",
    "            for image_batch, label_batch  in zip(images, labels):\n",
    "                feed_dict = {\n",
    "                    test_data_node: image_batch,\n",
    "                    test_labels_node: label_batch,\n",
    "                    is_training: False,\n",
    "                    keep_prob: 1.0 #During testing droput should be turned off -> 100% chance of keeping variable\n",
    "                }\n",
    "\n",
    "                dense_prediction, im = sess.run(fetches=[logits, pred], feed_dict=feed_dict)\n",
    "                per_class_acc(dense_prediction, label_batch)\n",
    "                # output_image to verify\n",
    "                if (SAVA_IMAGE):\n",
    "                    if(step < 10):\n",
    "                        numb_img = \"000\"+str(step)\n",
    "                    elif(step < 100):\n",
    "                        numb_img = \"00\"+str(step)\n",
    "                    elif(step < 1000):\n",
    "                        numb_img = \"0\"+str(step)\n",
    "                    write_image(im[0], os.path.join(res_output_dir +'/testing_image'+numb_img+'.png')) #Printing all test images\n",
    "                step=step+1\n",
    "                hist += get_hist(dense_prediction, label_batch)\n",
    "            acc_total = np.diag(hist).sum() / hist.sum()\n",
    "            iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "            print(\"acc: \", acc_total)\n",
    "            print(\"IU: \", iu)\n",
    "            print(\"mean IU: \", np.nanmean(iu))\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "def write_image(image, filename):\n",
    "    \"\"\" store label data to colored image \"\"\"\n",
    "    Sky = [0,0,0] #\n",
    "    Building = [128,128,0] #green-ish\n",
    "\n",
    "    r = image.copy()\n",
    "    g = image.copy()\n",
    "    b = image.copy()\n",
    "\n",
    "    label_colours = np.array([Sky, Building])\n",
    "    for label in range(0, NUM_CLASSES): #for all labels - shouldn't this be set according to num_class?\n",
    "        #Replacing all instances in matrix with label value with the label colour\n",
    "        r[image==label] = label_colours[label,0] #red is channel/debth 0\n",
    "        g[image==label] = label_colours[label,1] #green is channel/debth 1\n",
    "        b[image==label] = label_colours[label,2] #blue is channel/debth 2\n",
    "    rgb = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    rgb[:,:,0] = r/1.0\n",
    "    rgb[:,:,1] = g/1.0\n",
    "    rgb[:,:,2] = b/1.0\n",
    "    im = Image.fromarray(np.uint8(rgb))\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 10 images before starting to train. This will take a few minutes. \n"
     ]
    }
   ],
   "source": [
    "images, masks = distorted_inputs(data_dir=data_dir, validation=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 10 images before starting to train. This will take a few minutes. \n"
     ]
    }
   ],
   "source": [
    "val_images, val_masks = distorted_inputs(data_dir=data_dir, validation=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch:0' shape=(3, 256, 512, 3) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_node = tf.placeholder( tf.float32, shape=[3, 256, 512, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(3, 256, 512, 3) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape is:  (5, 256, 512, 64)\n",
      "pool1 shape is:  (5, 128, 256, 64)\n",
      "conv2 shape is:  (5, 128, 256, 64)\n",
      "pool2 shape is:  (5, 64, 128, 64)\n",
      "conv3 shape is:  (5, 64, 128, 64)\n",
      "pool3 shape is:  (5, 32, 64, 64)\n",
      "conv4 shape is:  (5, 32, 64, 64)\n",
      "pool4 shape is:  (5, 16, 32, 64)\n",
      "pool4 shape is:  (5, 16, 32, 64)\n",
      "unpool4 shape is:  (5, 32, 64, 64)\n",
      "conv_decode4 shape is:  (5, 32, 64, 64)\n",
      "\n",
      "pool3 shape is:  (5, 32, 64, 64)\n",
      "unpool_3 shape is:  (5, 64, 128, 64)\n",
      "conv_decode3 shape is:  (5, 64, 128, 64)\n",
      "\n",
      "pool2 shape is:  (5, 64, 128, 64)\n",
      "unpool_2 shape is:  (5, 128, 256, 64)\n",
      "conv_decode2 shape is:  (5, 128, 256, 64)\n",
      "\n",
      "pool1 shape is:  (5, 128, 256, 64)\n",
      "unpool_1 shape is:  (5, 256, 512, 64)\n",
      "conv_decode1 shape is:  (5, 256, 512, 64)\n",
      "\n",
      "conv shape is:  (5, 256, 512, 2)\n",
      "biases shape is:  (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_classifier/conv_classifier:0' shape=(5, 256, 512, 2) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "inference(images, BATCH_SIZE, phase_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 10 images before starting to train. This will take a few minutes. \n",
      "Filling queue with 10 images before starting to train. This will take a few minutes. \n",
      "conv1 shape is:  (3, 256, 512, 64)\n",
      "pool1 shape is:  (3, 128, 256, 64)\n",
      "conv2 shape is:  (3, 128, 256, 64)\n",
      "pool2 shape is:  (3, 64, 128, 64)\n",
      "conv3 shape is:  (3, 64, 128, 64)\n",
      "pool3 shape is:  (3, 32, 64, 64)\n",
      "conv4 shape is:  (3, 32, 64, 64)\n",
      "pool4 shape is:  (3, 16, 32, 64)\n",
      "pool4 shape is:  (3, 16, 32, 64)\n",
      "unpool4 shape is:  (3, 32, 64, 64)\n",
      "conv_decode4 shape is:  (3, 32, 64, 64)\n",
      "\n",
      "pool3 shape is:  (3, 32, 64, 64)\n",
      "unpool_3 shape is:  (3, 64, 128, 64)\n",
      "conv_decode3 shape is:  (3, 64, 128, 64)\n",
      "\n",
      "pool2 shape is:  (3, 64, 128, 64)\n",
      "unpool_2 shape is:  (3, 128, 256, 64)\n",
      "conv_decode2 shape is:  (3, 128, 256, 64)\n",
      "\n",
      "pool1 shape is:  (3, 128, 256, 64)\n",
      "unpool_1 shape is:  (3, 256, 512, 64)\n",
      "conv_decode1 shape is:  (3, 256, 512, 64)\n",
      "\n",
      "conv shape is:  (3, 256, 512, 2)\n",
      "biases shape is:  (2,)\n",
      "WARNING:tensorflow:From <ipython-input-17-f8c5242f511c>:15: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv_classifier/weight_loss (raw) is illegal; using conv_classifier/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name Mean_4 (raw) is illegal; using Mean_4__raw_ instead.\n",
      "2018-04-10 22:26:32.464619: step 0, loss = 0.89 (0.5 examples/sec; 6.030 sec/batch)\n",
      "accuracy = 0.782439\n",
      "mean IU  = 0.391219\n",
      "    class # 0 accuracy = 0.782439 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "start validating.....\n",
      "val loss:  0.0\n",
      "accuracy = nan\n",
      "mean IU  = nan\n",
      "    class # 0 accuracy = 0.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      " end validating.... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:104: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:107: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-10 22:26:44.719790: step 10, loss = 0.18 (4.3 examples/sec; 0.705 sec/batch)\n",
      "accuracy = 0.996726\n",
      "mean IU  = 0.498363\n",
      "    class # 0 accuracy = 0.996726 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:26:52.111802: step 20, loss = 0.05 (4.2 examples/sec; 0.713 sec/batch)\n",
      "accuracy = 0.997637\n",
      "mean IU  = 0.498819\n",
      "    class # 0 accuracy = 0.997637 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:26:59.534510: step 30, loss = 0.05 (4.2 examples/sec; 0.717 sec/batch)\n",
      "accuracy = 0.999835\n",
      "mean IU  = 0.499918\n",
      "    class # 0 accuracy = 0.999835 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:06.981497: step 40, loss = 0.02 (4.2 examples/sec; 0.716 sec/batch)\n",
      "accuracy = 0.999852\n",
      "mean IU  = 0.499926\n",
      "    class # 0 accuracy = 0.999852 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:14.444790: step 50, loss = 0.03 (4.2 examples/sec; 0.713 sec/batch)\n",
      "accuracy = 0.988535\n",
      "mean IU  = 0.494268\n",
      "    class # 0 accuracy = 0.988535 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:21.932634: step 60, loss = 0.03 (4.2 examples/sec; 0.721 sec/batch)\n",
      "accuracy = 0.999079\n",
      "mean IU  = 0.499540\n",
      "    class # 0 accuracy = 0.999079 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:29.434912: step 70, loss = 0.03 (4.2 examples/sec; 0.722 sec/batch)\n",
      "accuracy = 0.999974\n",
      "mean IU  = 0.499987\n",
      "    class # 0 accuracy = 0.999974 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:36.940659: step 80, loss = 0.03 (4.2 examples/sec; 0.718 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-10 22:27:44.459261: step 90, loss = 0.04 (4.2 examples/sec; 0.719 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:27:51.982860: step 100, loss = 0.08 (4.2 examples/sec; 0.718 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "start validating.....\n",
      "val loss:  0.0\n",
      "accuracy = nan\n",
      "mean IU  = nan\n",
      "    class # 0 accuracy = 0.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      " end validating.... \n",
      "2018-04-10 22:28:00.271506: step 110, loss = 0.05 (4.1 examples/sec; 0.723 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:07.811222: step 120, loss = 0.13 (4.2 examples/sec; 0.721 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:15.360454: step 130, loss = 0.05 (4.2 examples/sec; 0.721 sec/batch)\n",
      "accuracy = 0.974997\n",
      "mean IU  = 0.487499\n",
      "    class # 0 accuracy = 0.974997 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:22.916824: step 140, loss = 0.04 (4.1 examples/sec; 0.724 sec/batch)\n",
      "accuracy = 0.997257\n",
      "mean IU  = 0.498629\n",
      "    class # 0 accuracy = 0.997257 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:30.476861: step 150, loss = 0.03 (4.1 examples/sec; 0.725 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:38.045630: step 160, loss = 0.06 (4.1 examples/sec; 0.729 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:45.627456: step 170, loss = 0.05 (4.1 examples/sec; 0.728 sec/batch)\n",
      "accuracy = 0.999825\n",
      "mean IU  = 0.499913\n",
      "    class # 0 accuracy = 0.999825 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:28:53.222999: step 180, loss = 0.05 (4.1 examples/sec; 0.726 sec/batch)\n",
      "accuracy = 0.998471\n",
      "mean IU  = 0.499235\n",
      "    class # 0 accuracy = 0.998471 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:00.820414: step 190, loss = 0.04 (4.1 examples/sec; 0.725 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:08.430189: step 200, loss = 0.03 (4.1 examples/sec; 0.729 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "start validating.....\n",
      "val loss:  0.0\n",
      "accuracy = nan\n",
      "mean IU  = nan\n",
      "    class # 0 accuracy = 0.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      " end validating.... \n",
      "2018-04-10 22:29:16.795282: step 210, loss = 0.03 (4.1 examples/sec; 0.730 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:24.407938: step 220, loss = 0.03 (4.1 examples/sec; 0.727 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:32.027000: step 230, loss = 0.03 (4.1 examples/sec; 0.730 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:39.642649: step 240, loss = 0.02 (4.1 examples/sec; 0.724 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:47.263000: step 250, loss = 0.08 (4.1 examples/sec; 0.730 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:29:54.903961: step 260, loss = 0.02 (4.1 examples/sec; 0.730 sec/batch)\n",
      "accuracy = 0.955107\n",
      "mean IU  = 0.477554\n",
      "    class # 0 accuracy = 0.955107 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:02.532768: step 270, loss = 0.03 (4.1 examples/sec; 0.731 sec/batch)\n",
      "accuracy = 0.968508\n",
      "mean IU  = 0.484254\n",
      "    class # 0 accuracy = 0.968508 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:10.155317: step 280, loss = 0.03 (4.1 examples/sec; 0.728 sec/batch)\n",
      "accuracy = 0.999995\n",
      "mean IU  = 0.499997\n",
      "    class # 0 accuracy = 0.999995 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:17.791012: step 290, loss = 0.02 (4.1 examples/sec; 0.728 sec/batch)\n",
      "accuracy = 0.999997\n",
      "mean IU  = 0.499999\n",
      "    class # 0 accuracy = 0.999997 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:25.424774: step 300, loss = 0.02 (4.1 examples/sec; 0.731 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "start validating.....\n",
      "val loss:  0.0\n",
      "accuracy = nan\n",
      "mean IU  = nan\n",
      "    class # 0 accuracy = 0.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      " end validating.... \n",
      "2018-04-10 22:30:33.816274: step 310, loss = 0.03 (4.1 examples/sec; 0.732 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:41.447118: step 320, loss = 0.03 (4.1 examples/sec; 0.733 sec/batch)\n",
      "accuracy = 1.000000\n",
      "mean IU  = 1.000000\n",
      "    class # 0 accuracy = 1.000000 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "2018-04-10 22:30:49.101570: step 330, loss = 0.03 (4.1 examples/sec; 0.732 sec/batch)\n",
      "accuracy = 0.999971\n",
      "mean IU  = 0.499986\n",
      "    class # 0 accuracy = 0.999971 \n",
      "    class # 1 accuracy = 0.000000 \n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6603f0bcb3e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCONV_INIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"var_scale\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b4ee3b4131e5>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(is_finetune)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CONV_INIT = \"var_scale\"\n",
    "training(is_finetune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONV_INIT = \"var_scale\"\n",
    "# test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
